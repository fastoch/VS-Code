# Amazing New VS Code AI Coding Assistant with Open Source Models

sources: 
- https://www.youtube.com/watch?v=he0_W5iCv-I
- https://ollama.com/
- https://www.jeremymorgan.com/blog/generative-ai/how-to-install-ollama-web-ui-arch-linux/
- https://evalplus.github.io/leaderboard.html

---

## Intro

- a free AI coding assistant that we can use in VS Code
- it allows us to keep our code 100% local
- uses free open source models that are capable of giving us as good or even better results than we might be getting from a Copilot subscription

---

## Install Ollama

- start at https://ollama.com/
- download ollama for your OS and install it
- this might be helpful for Arch users: https://www.jeremymorgan.com/blog/generative-ai/how-to-install-ollama-web-ui-arch-linux/
- once you've installed ollama, start VS Code and open a terminal window
- run `ollama --version` to make sure it's been installed and is recognized by your system
- if this cmd is not recognized, reboot

---

## Add an Open Source Model / LLM (large language model)

- go to this page: https://evalplus.github.io/leaderboard.html
- this page is comparing free and paid models
- select your free model and go back to https://ollama.com/ to search for this model
- copy the command that will install the model: `ollama run <model_name>`
- paste it in your terminal window in VS Code, and run it
- downloading the model can take time depending on your connection and the model size

>[!note]
>codeqwen seems like a good choice of free AI model, it's pretty light (4.2GB) while ranked fifth in the EvalPlus Leaderboard
---

## Continue for VS Code

- now that you've installed Ollama and the desired free model, you need to add the ***Continue*** extension to VS code
- https://www.continue.dev/
- in VS code, go to the Extensions menu and search for "continue"
- install the extension

>[!tip]
>when opening Continue, you might get recommendations on the splash screen, just skip them, we don't want the splash screen

- a Continue icon will appear in the left pane, click it
- click on the gear icon to configure Continue
- inside this config.json file, you can see:
  - the available models
    - the default model is listed at the top
  - the custom commands
    - for ex, if we type "test" into the chat, it will run the specified prompt against the current AI model
  - then you can specify the desired tabAutocompleteModel

### Custom command example

- select the existing custom command and press Shift+Ctrl+Alt + the down arrow to copy-paste it
- put a comma after the first custom command (after the closing curly bracket)
- in this new custom command:
  - set the "name" value to "step"
  - set the "prompt" value to "explain the selected code step by step"
  - set the "description" value to "code explanation"
- now you can write some code and try your new custom command in the chat window

---

## Code Chats & Autocompletions

### AI-Generated Code example

- we can create a .js file named "convertToMySQLTimestamp.js"
- after that we can press Ctrl+I to provide instructions that will generate code for us
- we could type: "write a function that accepts a javascript date as a parameter and returns a MySQL timestamp"
- we can then highlight the code generated by the AI and then Ctrl+L to copy it from the editor to the chat
- after that, I can ask in the chat: "would this be more efficient if you used toISOString()?"
- I can also ask a question to generate code in the chat: "can you write the function with toISOString()?"
- and then I can **apply** the newly generated code **to the current file**

>[!tip]
>The help button in the chat (circle with ?) shows shortcuts, useful links and a hidden tutorial

>[!warning]
>Of course you don't want to just trust AI, you got to check the validity of any AI-generated code

### Other example

- create a .py file anmed "api.py" 
- press Ctrl +I and type "write a python rest api using fastapi and sqlalchemy"

